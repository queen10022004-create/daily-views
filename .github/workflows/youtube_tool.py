import os
import datetime
import pandas as pd
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

class YouTubeAnalyticsTool:
    def __init__(self, api_key):
        self.youtube = build('youtube', 'v3', developerKey=api_key)

    def get_channel_id_by_handle(self, handle):
        try:
            request = self.youtube.search().list(part="snippet", q=handle, type="channel", maxResults=1)
            response = request.execute()
            if response['items']:
                return response['items'][0]['snippet']['channelId']
            return None
        except HttpError as e:
            print(f"L·ªói khi t√¨m k√™nh: {e}")
            return None

    def get_uploads_playlist_id(self, channel_id):
        request = self.youtube.channels().list(part="contentDetails", id=channel_id)
        response = request.execute()
        try:
            return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']
        except (IndexError, KeyError):
            return None

    def get_all_videos_stats(self, playlist_id):
        videos_data = []
        next_page_token = None
        print("üîÑ ƒêang l·∫•y d·ªØ li·ªáu t·ª´ YouTube API...")

        while True:
            pl_request = self.youtube.playlistItems().list(
                part="contentDetails", playlistId=playlist_id, maxResults=50, pageToken=next_page_token
            )
            pl_response = pl_request.execute()
            video_ids = [item['contentDetails']['videoId'] for item in pl_response['items']]

            if video_ids:
                vid_request = self.youtube.videos().list(part="snippet,statistics", id=','.join(video_ids))
                vid_response = vid_request.execute()

                for item in vid_response['items']:
                    stats = item['statistics']
                    snippet = item['snippet']
                    videos_data.append({
                        'Video ID': item['id'],
                        'Title': snippet['title'],
                        'Publish Date': snippet['publishedAt'],
                        'Link': f"https://www.youtube.com/watch?v={item['id']}",
                        'Views': int(stats.get('viewCount', 0))
                    })

            next_page_token = pl_response.get('nextPageToken')
            if not next_page_token:
                break
        return videos_data

    def update_history_csv(self, current_data, filename):
        if not current_data:
            print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu.")
            return

        today_str = datetime.datetime.now().strftime('%Y-%m-%d')
        view_col_today = f'Views_{today_str}'

        df_today = pd.DataFrame(current_data)
        df_today.rename(columns={'Views': view_col_today}, inplace=True)

        if os.path.exists(filename):
            print(f"üìÇ ƒêang c·∫≠p nh·∫≠t v√†o file l·ªãch s·ª≠ c≈©: {filename}")
            df_hist = pd.read_csv(filename)
            
            # --- ƒê√ÇY L√Ä ƒêO·∫†N FIX L·ªñI CH·∫†Y TR√ôNG NG√ÄY ---
            # N·∫øu file c≈© ƒë√£ c√≥ c·ªôt c·ªßa ng√†y h√¥m nay, ta x√≥a n√≥ ƒëi ƒë·ªÉ ghi ƒë√® d·ªØ li·ªáu m·ªõi nh·∫•t
            if view_col_today in df_hist.columns:
                df_hist.drop(columns=[view_col_today], inplace=True)
            # ------------------------------------------

            old_view_cols = [col for col in df_hist.columns if col.startswith('Views_') and '-' in col]
            df_hist_views_only = df_hist[['Video ID'] + old_view_cols]
            df_final = pd.merge(df_today, df_hist_views_only, on='Video ID', how='outer')
            
            if old_view_cols:
                last_date_col = old_view_cols[-1]
                df_final['Views_Gained'] = df_final[view_col_today].fillna(0) - df_final[last_date_col].fillna(0)
            else:
                df_final['Views_Gained'] = 0
        else:
            print(f"üÜï T·∫°o file l·ªãch s·ª≠ m·ªõi: {filename}")
            df_final = df_today
            df_final['Views_Gained'] = 0

        df_final = df_final.fillna(0)
        cols = df_final.columns.tolist()
        if 'Views_Gained' in cols:
            cols.insert(4, cols.pop(cols.index('Views_Gained')))
        
        df_final = df_final[cols].sort_values(by=view_col_today, ascending=False)
        df_final.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"‚úÖ ƒê√£ l∆∞u file th√†nh c√¥ng: {filename}")

if __name__ == "__main__":
    # 1. L·∫•y Key
    API_KEY = os.environ.get('API_KEY')
    if not API_KEY:
        API_KEY = os.environ.get('YOUTUBE_API_KEY') 

    if not API_KEY:
        print("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y API Key.")
        exit(1)

    # 2. C·∫•u h√¨nh k√™nh
    CHANNEL_HANDLE = '@stoicether' 
    
    # 3. ƒê·∫∂T T√äN FILE (QUAN TR·ªåNG NH·∫§T - PH·∫¢I N·∫∞M ·ªû ƒê√ÇY)
    CSV_FILENAME = f"history_{CHANNEL_HANDLE.replace('@','')}.csv"
    
    # 4. Ch·∫°y tool
    tool = YouTubeAnalyticsTool(API_KEY)
    channel_id = tool.get_channel_id_by_handle(CHANNEL_HANDLE)

    if channel_id:
        uploads_id = tool.get_uploads_playlist_id(channel_id)
        if uploads_id:
            data = tool.get_all_videos_stats(uploads_id)
            # L√∫c n√†y bi·∫øn CSV_FILENAME ƒë√£ ƒë∆∞·ª£c t·∫°o ·ªü b∆∞·ªõc 3 n√™n s·∫Ω kh√¥ng l·ªói n·ªØa
            tool.update_history_csv(data, CSV_FILENAME)
        else:
             print("‚ùå Kh√¥ng t√¨m th·∫•y playlist Uploads.")
    else:
        print("‚ùå Kh√¥ng t√¨m th·∫•y k√™nh.")


